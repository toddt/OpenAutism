{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is edited from the first version to pull in a master list created by Dima and \n",
    "# use that as the ground truth for how many subjects and runs we have. Each masterlist corresponds to \n",
    "# either pilot data or analysis data. MAKE SURE TO UPDATE THIS CSV LIST WHEN DIMA IS DONE (this is not a dynamic file)\n",
    "\n",
    "# Extra files are eliminated from the analysis in the Creating_TIER_Directory script.\n",
    "\n",
    "# import modules\n",
    "from glob import glob\n",
    "import re\n",
    "import os.path\n",
    "from itertools import repeat\n",
    "import csv\n",
    "from shutil import copyfile\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "pilot = 1\n",
    "\n",
    "if pilot == 1:\n",
    "    masterlist = \"/om/user/rezzo/TOMLOC_INFO/tomloc_subject_info_internal.csv\"\n",
    "else:\n",
    "    masterlist = '/om/group/saxelab/OpenAutism/data/Subject_Task_Info_Dima/subject_info_internal.csv'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_between( s, first, last ):\n",
    "    try:\n",
    "        start = s.index( first ) + len( first )\n",
    "        end = s.index( last, start )\n",
    "        return s[start:end]\n",
    "    except ValueError:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file/directory not found\n",
      "/om/group/saxelab/OpenAutism/Analysis/first_level_aroma.py/TASTI2/sub-SAXtasti201/tomloc/model/run1\n",
      "file/directory not found\n",
      "/om/group/saxelab/OpenAutism/Analysis/first_level_aroma.py/TASTI2/sub-SAXtasti201/tomloc/model/run2\n",
      "file/directory not found\n",
      "/om/group/saxelab/OpenAutism/Analysis/first_level_aroma.py/TASTI2/sub-SAXtasti202/tomloc/model/run1\n",
      "file/directory not found\n",
      "/om/group/saxelab/OpenAutism/Analysis/first_level_aroma.py/TASTI2/sub-SAXtasti202/tomloc/model/run2\n",
      "file/directory not found\n",
      "/om/group/saxelab/OpenAutism/Analysis/first_level_aroma.py/TASTI2/sub-SAXtasti203/tomloc/model/run1\n",
      "file/directory not found\n",
      "/om/group/saxelab/OpenAutism/Analysis/first_level_aroma.py/TASTI2/sub-SAXtasti203/tomloc/model/run2\n",
      "file/directory not found\n",
      "/om/group/saxelab/OpenAutism/Analysis/first_level_aroma.py/TASTI2/sub-SAXtasti205/tomloc/model/run1\n",
      "file/directory not found\n",
      "/om/group/saxelab/OpenAutism/Analysis/first_level_aroma.py/TASTI2/sub-SAXtasti205/tomloc/model/run2\n",
      "file/directory not found\n",
      "/om/group/saxelab/OpenAutism/Analysis/first_level_aroma.py/TASTI2/sub-SAXtasti206/tomloc/model/run1\n",
      "file/directory not found\n",
      "/om/group/saxelab/OpenAutism/Analysis/first_level_aroma.py/TASTI2/sub-SAXtasti206/tomloc/model/run2\n",
      "file/directory not found\n",
      "/om/group/saxelab/OpenAutism/Analysis/first_level_aroma.py/TASTI2/sub-SAXtasti207/tomloc/model/run1\n",
      "file/directory not found\n",
      "/om/group/saxelab/OpenAutism/Analysis/first_level_aroma.py/TASTI2/sub-SAXtasti207/tomloc/model/run2\n"
     ]
    }
   ],
   "source": [
    "root = '/om/group/saxelab/OpenAutism/data/' #+site+'/'+subject_name+'/dicom'\n",
    "other_folders = ['mriqc_output', 'BIDS', '_OLD_', 'SPM_firstlevel']\n",
    "\n",
    "all_files = []\n",
    "missing_dicoms = []\n",
    "missing_anat = []\n",
    "missing_func_folder = []\n",
    "missing_bids = []\n",
    "missing_func_file = []\n",
    "missing_fmriprep = []\n",
    "missing_generaltsv = []\n",
    "missing_mriqc_T1 = []\n",
    "missing_fmriprep_smoothpreproc = []\n",
    "missing_fmriprep_confounds = []\n",
    "missing_mriqc_func = []\n",
    "missing_firstlevel = []\n",
    "missing_firstleveltime = []\n",
    "\n",
    "with open(masterlist, \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter=\",\")\n",
    "    for i, line in enumerate(reader):\n",
    "        if any(line) and (i != 0):\n",
    "        #if (i != 0):\n",
    "                subject_id = line[1] #SAX_SUB_ID\n",
    "                subject_id2 = subject_id.replace(\"_\",\"\") #SAXSUBID\n",
    "                site_id = line[3]\n",
    "                task_id = line[4].replace(\"_\",\"\")\n",
    "                run_id = line[6].split(\",\")\n",
    "\n",
    "                all_files.append(subject_id+'_'+site_id+'_'+task_id)\n",
    "\n",
    "                # check for dicom folder\n",
    "                dicom_dir = os.listdir(root+site_id+'/'+subject_id+'/')\n",
    "                if 'dicom' not in dicom_dir:\n",
    "                    missing_dicoms.append(site_id+subject_id)\n",
    "                else:\n",
    "                    missing_dicoms.append(\"\")\n",
    "                        \n",
    "                # check for BIDS folder\n",
    "                if os.path.isdir(root+site_id+'/BIDS/sub-'+subject_id2+'/'):\n",
    "                    missing_bids.append(\"\")\n",
    "                        \n",
    "                    # check for BIDS tsv file\n",
    "                    if not (os.path.isfile(root+site_id+'/BIDS/sub-'+subject_id2+'/sub-'+subject_id2+\"_scans.tsv\")):\n",
    "                        missing_generaltsv.append(sites+subjects)   \n",
    "                    else:\n",
    "                        missing_generaltsv.append(\"\")  \n",
    "\n",
    "                    # check for BIDS anat file\n",
    "                    if not (os.path.isfile(root+site_id+'/BIDS/sub-'+subject_id2+'/anat/'+'sub-'+subject_id2+'_T1w.json') and os.path.isfile(root+site_id+'/BIDS/sub-'+subject_id2+'/anat/'+'sub-'+subject_id2+'_T1w.nii.gz')):\n",
    "                        missing_anat.append(sites+subjects)\n",
    "                    else:\n",
    "                        missing_anat.append(\"\")\n",
    "                            \n",
    "                    # check for functionals\n",
    "                    missing_task = 0\n",
    "                    missing_functional = 0\n",
    "                    for jj in run_id:\n",
    "                        jj = jj.replace(\" \", \"\")\n",
    "                        num = int(jj) -1\n",
    "                        \n",
    "                        # is BIDS FUNC folder present?\n",
    "                        if os.path.isdir(root+site_id+'/BIDS/sub-'+subject_id2+'/func/'):\n",
    "                            func_files = os.listdir(root+site_id+'/BIDS/sub-'+subject_id2+'/func/')                            \n",
    "                            missing_functional = 0\n",
    "                            \n",
    "                            json_f = os.path.isfile(root+site_id+'/BIDS/sub-'+subject_id2+'/func/sub-'+subject_id2+'_task-'+task_id+'_run-00'+jj+'_bold.json')\n",
    "                            nifti_f = os.path.isfile(root+site_id+'/BIDS/sub-'+subject_id2+'/func/sub-'+subject_id2+'_task-'+task_id+'_run-00'+jj+'_bold.nii.gz')\n",
    "                            events_f = os.path.isfile(root+site_id+'/BIDS/sub-'+subject_id2+'/func/sub-'+subject_id2+'_task-'+task_id+'_run-00'+jj+'_events.tsv')\n",
    "                            \n",
    "                            if (json_f + nifti_f + events_f == 3):\n",
    "                                missing_task = 0\n",
    "                            else:\n",
    "                                missing_task = missing_task + 1\n",
    "                        else:\n",
    "                            missing_task = 1\n",
    "                            missing_functional = 1 \n",
    "                    \n",
    "                    if missing_task > 0:\n",
    "                        missing_func_file.append(site_id+subject_id)\n",
    "                    elif missing_task == 0:\n",
    "                        missing_func_file.append(\"\") \n",
    "                        \n",
    "                    if missing_functional > 0:\n",
    "                        missing_func_folder.append(site_id+subject_id)\n",
    "                    elif missing_functional == 0:\n",
    "                        missing_func_folder.append(\"\") \n",
    "                                                      \n",
    "                        \n",
    "                else: # if BIDS folder does not exist, claim all files within missing\n",
    "                    missing_bids.append(site_id+'_'+subject_id)   \n",
    "                    missing_generaltsv.append(site_id+'_'+subject_id)  \n",
    "                    missing_anat.append(site_id+'_'+subject_id)\n",
    "                    missing_func.append(site_id+'_'+subject_id)  \n",
    "\n",
    "                    \n",
    "                # LOOK AT FMRIPREP\n",
    "                missing_fmriprep_funcs = 0\n",
    "                missing_fmriprep_confs = 0\n",
    "                for jj in run_id:\n",
    "                    jj = jj.replace(\" \", \"\")\n",
    "                    num = int(jj) -1\n",
    "                \n",
    "                try:  \n",
    "                    listdir = os.listdir(root+site_id+'/BIDS/derivatives/fmriprep/sub-'+subject_id2+'/func/')\n",
    "                    missing_fmriprep.append(\"\")\n",
    "                    preproc = \"sub-\"+subject_id2+\"_task-\"+task_id+'_run-00'+jj+\"_bold_space-MNI152NLin2009cAsym_variant-smoothAROMAnonaggr_preproc.nii.gz\"\n",
    "                    confounds = \"sub-\"+subject_id2+\"_task-\"+task_id+'_run-00'+jj+\"_bold_confounds.tsv\"\n",
    "                        \n",
    "                    if preproc not in listdir:\n",
    "                        missing_fmriprep_funcs = 1\n",
    "                    if confounds not in listdir:\n",
    "                        missing_fmriprep_confs = 1\n",
    "                except FileNotFoundError:\n",
    "                    missing_fmriprep.append(site_id+subject_id)\n",
    "                    missing_fmriprep_funcs = 1\n",
    "                    missing_fmriprep_confs = 1\n",
    "                    \n",
    "                if missing_fmriprep_funcs == 0:\n",
    "                    missing_fmriprep_smoothpreproc.append(\"\")\n",
    "                else:\n",
    "                    missing_fmriprep_smoothpreproc.append(site_id+subject_id)\n",
    "                    \n",
    "                if missing_fmriprep_confs == 0:\n",
    "                    missing_fmriprep_confounds.append(\"\")\n",
    "                else:\n",
    "                    missing_fmriprep_confounds.append(site_id+subject_id)\n",
    "                   \n",
    "                \n",
    "                # LOOK AT MRIQC\n",
    "                quality = 0\n",
    "                \n",
    "                try: \n",
    "                    tempdir = os.listdir(root+site_id+'/mriqc_output/reports/')\n",
    "                    if r\"sub-\"+subject_id2+\"_T1w.html\" in tempdir:\n",
    "                        missing_mriqc_T1.append(\"\")\n",
    "                    else:\n",
    "                        missing_mriqc_T1.append(site_id+subject_id)\n",
    "                        \n",
    "                    for jj in run_id:\n",
    "                        jj = jj.replace(\" \", \"\")\n",
    "                        num = int(jj) -1\n",
    "                        \n",
    "                        # fix below!\n",
    "                        QI = \"sub-\"+subject_id2+\"_task-\"+task_id+'_run-00'+jj+\"_bold.html\"\n",
    "                        if QI not in tempdir:\n",
    "                            quality = 1\n",
    "                except FileNotFoundError:\n",
    "                    missing_mriqc_T1.append(site_id+subject_id)\n",
    "                    quality = 1\n",
    "                    \n",
    "                if quality == 0:\n",
    "                    missing_mriqc_func.append(\"\")\n",
    "                else:\n",
    "                    missing_mriqc_func.append(site_id+subject_id) \n",
    "                    \n",
    "                # look at first level anayses ######## DONE UNTIL HERE\n",
    "                first_lev_error = 0\n",
    "                first_level_timeseries_error = 0\n",
    "                firstleveldir = '/om/group/saxelab/OpenAutism/Analysis/first_level_standard.py/'+ site_id+'/sub-'+subject_id2\n",
    "                firstleveltimedir = '/om/group/saxelab/OpenAutism/Analysis/first_level_standard_timeseries.py/'+ site_id+'/sub-'+subject_id2\n",
    "                sites_low = site_id.lower()\n",
    "\n",
    "                if os.path.isdir(firstleveldir) or os.path.isdir(firstleveltimedir):\n",
    "                    for jj in run_id:\n",
    "                        jj = jj.replace(\" \", \"\")\n",
    "                        num = int(jj) -1        \n",
    "\n",
    "                        firstleveldir = '/om/group/saxelab/OpenAutism/Analysis/first_level_aroma.py/'+site_id+'/sub-'+subject_id2+'/'+task_id+'/model/'+'run'+jj\n",
    "                        firstleveltimedir = '/om/group/saxelab/OpenAutism/Analysis/first_level_standard_timeseries.py/'+ site_id+'/sub-'+subject_id2+'/'+task_id+'/model/'+'run'+jj\n",
    "                        try:\n",
    "                            if len(os.listdir(firstleveldir) ) == 0:\n",
    "                                first_lev_error = 1\n",
    "                        except FileNotFoundError:\n",
    "                            print('file/directory not found')\n",
    "                            print(firstleveldir)\n",
    "                            first_lev_error = 1\n",
    "                        try: #added\n",
    "                            if len(os.listdir(firstleveltimedir) ) == 0:\n",
    "                                first_level_timeseries_error = 1\n",
    "                        except FileNotFoundError:\n",
    "                            print('file/directory not found')\n",
    "                            print(firstleveltimedir)\n",
    "                            first_level_timeseries_error = 1\n",
    "                            \n",
    "                else:\n",
    "                    if os.path.isdir(firstleveldir) == 0:\n",
    "                        #print(\"no FL folder\")\n",
    "                        first_lev_error = 1\n",
    "                    if os.path.isdir(firstleveltimedir) == 0: # in addition\n",
    "                        #print(\"no FL tmeseries folder\")\n",
    "                        first_level_timeseries_error = 1\n",
    "                  \n",
    "                if first_lev_error == 0:\n",
    "                    missing_firstlevel.append(\"\")\n",
    "                else:\n",
    "                    missing_firstlevel.append(site_id+subject_id) \n",
    "                    \n",
    "                if first_level_timeseries_error == 0:\n",
    "                    missing_firstleveltime.append(\"\")\n",
    "                else:\n",
    "                    missing_firstleveltime.append(site_id+subject_id) \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "d = {'all_files': all_files, 'missing_dicoms': missing_dicoms, 'missing_bids': missing_bids,\n",
    "'missing_generaltsv': missing_generaltsv, 'missing_anat':missing_anat, 'missing_func':missing_anat,\n",
    "'missing_fmriprep':missing_fmriprep, 'missing_fmriprep_smoothpreproc':missing_fmriprep_smoothpreproc,\n",
    "'missing_fmriprep_confounds':missing_fmriprep_confounds,'missing_mriqc_T1':missing_mriqc_T1,\n",
    "'missing_mriqc_func':missing_mriqc_func, 'missing_firstlevel':missing_firstlevel, 'missing_firstleveltime': missing_firstleveltime}\n",
    "    \n",
    "df = pd.DataFrame(data=d, columns=['all_files', 'missing_dicoms', 'missing_bids','missing_generaltsv', 'missing_anat', 'missing_func', \n",
    "                                  'missing_fmriprep', 'missing_fmriprep_smoothpreproc', 'missing_fmriprep_confounds','missing_mriqc_T1', 'missing_mriqc_func', 'missing_firstlevel','missing_firstleveltime'])\n",
    "\n",
    "if pilot == 1:\n",
    "    df.to_csv('/om/user/rezzo/list_of_missing_tomloc_files')\n",
    "else:\n",
    "    df.to_csv('/om/user/rezzo/list_of_missing_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
